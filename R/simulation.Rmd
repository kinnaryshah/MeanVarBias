```{r}
library(SpatialExperiment)
library(STexampleData)
library(MASS)
library(scuttle)

set.seed(1)

### GENERATING DATA

#4992 spots and 2000 genes

n_genes <- 2000
fraction <- 0.5
max_sigma.sq <- 1
low_range_beta <- c(0.5,1)
#high_range_beta <- c(4,8)

#check if integer
stopifnot(n_genes*fraction*0.5 == round(n_genes*fraction*0.5))

#all genes have some nonzero sigma.sq
sigma.sq <- runif(n_genes, 0.2, max_sigma.sq)
ground_truth_rank <- rank(-sigma.sq)

#all genes will have nonzero beta values
beta <- runif(n_genes, log(low_range_beta[1]), log(low_range_beta[2]))

#choose fixed length scale parameter (~medium from nnSVG paper)

scale_length <- 200

params <- data.frame(sigma.sq, beta)

plot(beta, sigma.sq)

#sampling from a poisson distribution - mean controls variance, so we don't specify tau.sq:
#step 1: use ST example distance matrix instead of creating a new one (Euclidean distance)

spe_demo <- Visium_humanDLPFC()
points_coord <- spatialCoords(spe_demo)
n_points <- nrow(points_coord)

pair.points <- cbind(
  matrix( rep(points_coord, each = n_points), ncol = 2, byrow = FALSE),
  rep(1, times = n_points) %x% points_coord # Creating the combinations using kronecker product.
) |> data.frame()
colnames(pair.points) <- c("si.x", "si.y", "sj.x", "sj.y")

#step 2: calculate gaussian process/kernel 

kernel.fun <- function(si.x, si.y, sj.x, sj.y,  l = 0.2){
  exp(-1*sqrt(((si.x-sj.x)^2+(si.y-sj.y)^2))/l)
}

C_theta <- with(pair.points, kernel.fun(si.x, si.y, sj.x, sj.y, l = scale_length)) |> 
  matrix(nrow = n_points, ncol = n_points)

counts <- matrix(NA, nrow = n_genes, ncol = n_points)
eta_list <- list()

for (i in c(1:n_genes)) {
  
  print(i)
  sigma.sq_i <- sigma.sq[i]
  beta_i <- beta[i]
  print(paste0(sigma.sq_i, " ", beta_i))
  
  #step 3: simulate gaussian process per gene
  
  gp_dat <- mvrnorm(n = 1, rep(0,n_points), sigma.sq_i* C_theta) 

  #step 4: calculate lambda = exp(beta + gaussian process) per gene
  
  #eta_i <- mean(gp_dat + beta_i)
  #eta_list <- append(eta_list, eta_i)
  #lambda_i <- exp(eta_i)
  lambda_i <- exp(gp_dat + beta_i)

  #step 5: use rpois() to simulate 4992 values per gene

  counts_i <- rpois(n = n_points, lambda_i)
  
  #put all counts in matrix 
  #orientation: genes x spots
  
  counts[i,] <- counts_i
}

pdf("beta_eta_simulation.pdf", width = 21, height = 10)
plot(beta, unlist(eta_list))
dev.off()

#create spe using counts and distance matrix

spe <- SpatialExperiment(
    assays = list(counts = counts),
    spatialCoords = points_coord)

rowData(spe)$ground_truth <- ground_truth
rowData(spe)$ground_truth_rank <- ground_truth_rank
rowData(spe)$ground_truth_sigma.sq <- sigma.sq
rowData(spe)$ground_truth_beta <- beta

saveRDS(spe, file = "spe_simulation.rds")

```

```{r}
library(SpatialExperiment)
library(ggplot2)
library(spatialLIBD)
library(nnSVG)
library(BRISC)
library(BiocParallel)
library(scuttle)

### USING THE DATA

spe <- readRDS(file = "mean_var_project/spe_simulation.rds")
spe <- spe[, colSums(counts(spe)) > 0]
dim(spe)

spe <- logNormCounts(spe)

# plot spatial expression of top ground truth SVG
ix <- which(rowData(spe)$ground_truth_rank == 200)

ix <- 1
df <- as.data.frame(cbind(spatialCoords(spe), expr = logcounts(spe)[ix, ]))

ggplot(df, aes(x = pxl_col_in_fullres, y = pxl_row_in_fullres, 
               color = expr)) + 
  geom_point(size = 0.8) + 
  coord_fixed() + 
  scale_y_reverse() + 
  scale_color_viridis_c(name = "logcounts") + 
  ggtitle("top ground truth, beta=0.28") + 
  theme_bw() + 
  theme(plot.title = element_text(face = "italic"), 
        panel.grid = element_blank(), 
        axis.title = element_blank(), 
        axis.text = element_blank(), 
        axis.ticks = element_blank())

#calculate weights

# Count Matrix, transpose so each row is a spot, and each column is a gene
r <- t(as.matrix(counts(spe)))

n <- dim(spe)[2] # Number of Cells
G <- dim(spe)[1] # Number of Genes

# Sample-specific Library Size
R <- rowSums(r)
stopifnot(length(R)==n)

# Temporary Matrix, replicate library size for each row
tmp_R_mat <- matrix(
  rep(R, each = G),
  byrow = TRUE, nrow = n, ncol = G
)

# logCPM
y <- log2(r+0.5) - log2(tmp_R_mat+1) + log2(10^6)


# Viz Mean-variance -------------------------------------------------------
data.frame(
  y = apply(y, MARGIN = 2, sd) |>
    sqrt(),   # Square root of the standard deviation of logCPM (y_i)
  x = log(r+0.5, base = 2) |>
    colMeans(), # log2(r_i + 0.5)
  ground_truth = rowData(spe)$ground_truth
) |>
  ggplot() +
  geom_point(aes(x = x, y = y, color = ground_truth)) +
  labs(
    x = "log2(count size + 0.5)",
    y = "Sqrt(standard deviation)"
  ) 
  



# Calc Weight -------------------------------------------------------------

# *BRISC ----------------------------------------------------------

coords <- spatialCoords(spe)

# scale coordinates proportionally
range_all <- max(apply(coords, 2, function(col) diff(range(col))))
coords <- apply(coords, 2, function(col) (col - min(col)) / range_all)

# calculate ordering of coordinates
order_brisc <- BRISC_order(coords, order = "AMMD", verbose = F)

# calculate nearest neighbors
nn_brisc <- BRISC_neighbor(coords, n.neighbors = 10, n_omp = 1, 
                           search.type = "tree", ordering = order_brisc, 
                           verbose = F)

  
# run BRISC using parallelization
# run BRISC by column of y so BRISC is run per gene
ix <- seq_len(ncol(y))
#ix <- c(1,2,3)
out_brisc <- bplapply(ix, function(i) {
  # fit model (intercept-only model if x is NULL)
  y_i <- y[ ,i]
  suppressWarnings({
    runtime <- system.time({
      out_i <- BRISC_estimation(coords = coords, y = y_i, x = NULL, 
                                cov.model = "exponential", 
                                ordering = order_brisc, neighbor = nn_brisc, 
                                verbose = F)
    })
  })
  
  pred_i <- BRISC_prediction(out_i, coords = coords, X.0 = NULL, verbose = F)
  residual_i <- y_i - pred_i$prediction
  
  return(list(pred_i$prediction, residual_i))
}, BPPARAM = MulticoreParam(workers = 20)) #change to 20 on JHPCE

# collapse output list into matrix
mat_brisc <- do.call("rbind", out_brisc)

# *Voom Variance Modelling -------------------------------------------------

mu_hat <- unname(as.matrix(as.data.frame(mat_brisc[,1])))
stopifnot(dim(mu_hat) == c(n, G))

s_g <- unname(as.data.frame(mat_brisc[,2])) |> 
  apply(MARGIN = 2,  # Column wise
        FUN = sd)
stopifnot(length(s_g) == G)

y_bar <- colMeans(mu_hat)
stopifnot(length(y_bar) == G)

# Geometric Mean
R_tilda <- exp(mean(log(R)))
# The reason of calculating log is to avoid integer overflow

# Log2 Counts
# Note: slight notation abuse. Prev r denotes read counts
r_tilda <- y_bar + log2(R_tilda) - log2(10^6)
stopifnot(length(r_tilda)==G)

# *Plot Relationship -----------------------------------------------------


# data.frame(
#   y = sqrt(s_g),
#   x = r_tilda
# ) |> 
#   ggplot() +
#   geom_point(aes(x = x, y = y)) +
#   geom_smooth(aes(x = x, y = y)) +
#   labs(
#     x = "log2(count size)",
#     y = "Sqrt(s_g)"
#   )

library(ggformula)
p1 <- data.frame(
  y = sqrt(s_g),
  x = r_tilda,
  ground_truth = rowData(spe)$ground_truth
) |> 
  ggplot() +
  geom_point(aes(x = x, y = y, color = ground_truth)) +
  geom_smooth(aes(x = x, y = y), method = "loess") +
  stat_spline(aes(x = x, y = y), nknots=4) +
  labs(
    x = "log2(count size)",
    y = "Sqrt(s_g)"
  )
  
ggsave("relationship_simulation.png", plot = p1)

# *PREDICT MODEL -----------------------------------------------------------------
stopifnot(dim(mu_hat)==dim(tmp_R_mat))
lambda_hat <- mu_hat + log2(tmp_R_mat+1) - log2(10^6)

#gives percentage of lambda_hat values out of range
sum(lambda_hat < range(r_tilda)[1] | lambda_hat > range(r_tilda)[2]) / (dim(spe)[1]*dim(spe)[2]) 
sum(lambda_hat < range(r_tilda)[1]) / (dim(spe)[1]*dim(spe)[2])
sum(lambda_hat > range(r_tilda)[2]) / (dim(spe)[1]*dim(spe)[2])

spline_fit <- smooth.spline(y=sqrt(s_g), x=r_tilda)

# NOTE: It is possible that lambda is out of range of r_tilda
# which will produce NA predicted values due to extrapolation
tmp_pred_sqrt_sg <- predict(
  spline_fit, 
  x = c(lambda_hat)
 )$y |> 
  matrix(
    nrow = n, ncol = G
  )

w <- tmp_pred_sqrt_sg^(-4) 

save(w, spline_fit, s_g, r_tilda, lambda_hat, file = "simulation_BRISC_estimation_spline.rds")
```

```{r}
library(nnSVG)
library(SpatialExperiment)
library(scuttle)

#run nnSVG on the logcounts matrix
spe <- readRDS(file = "spe_simulation.rds")

spe <- spe[, colSums(counts(spe)) > 0]
dim(spe)

spe <- logNormCounts(spe)

#run nnSVG on the logcounts matrix
set.seed(2)
spe_unweighted <- nnSVG(spe, assay_name = "logcounts")

#run weighted nnSVG on the logcounts matrix

load(file = "simulation_BRISC_estimation_spline.rds")
weighted_logcounts <- t(w)*logcounts(spe)
assay(spe, "weighted_logcounts") <- weighted_logcounts # assign a new entry to assays slot, nnSVG will use "logcounts" by default

# Make sure nnSVG fixed the interceptless model 
stopifnot(
  "Please update your nnSVG to minimum v1.5.3 to have the correct result" = 
    packageVersion("nnSVG")>='1.5.3'
)

#run nnSVG with covariate
weighted_nnSVG_calc <- function(i){
  res = tryCatch({
  weight_output_i <- nnSVG(spe[i,], X=matrix(w[,i]), assay_name = "weighted_logcounts")
  list(weighted_LR_stat = rowData(weight_output_i)$LR_stat,
       weighted_mean = rowData(weight_output_i)$mean,
       weighted_var = rowData(weight_output_i)$var,
       weighted_sigma.sq = rowData(weight_output_i)$sigma.sq,
       weighted_tau.sq = rowData(weight_output_i)$tau.sq,
       weighted_prop_sv = rowData(weight_output_i)$prop_sv)
}, error=function(e){
  cat("ERROR :",conditionMessage(e), "\n")
  list(weighted_LR_stat = NA,
       weighted_mean = NA,
       weighted_var = NA,
       weighted_sigma.sq = NA,
       weighted_tau.sq = NA,
       weighted_prop_sv = NA)
  })
  return(res)
}

dim(matrix(assays(spe)$weighted_logcounts[i,],ncol=4992))

weighted_nnSVG_calc <- function(i){
  res = tryCatch({
  weight_output_i <- nnSVG(input = matrix(assays(spe)$weighted_logcounts[i,],ncol=4992), spatial_coords = spatialCoords(spe), X = matrix(w[,i]))
  list(weighted_LR_stat = rowData(weight_output_i)$LR_stat,
       weighted_mean = rowData(weight_output_i)$mean,
       weighted_var = rowData(weight_output_i)$var,
       weighted_sigma.sq = rowData(weight_output_i)$sigma.sq,
       weighted_tau.sq = rowData(weight_output_i)$tau.sq,
       weighted_prop_sv = rowData(weight_output_i)$prop_sv)
}, error=function(e){
  cat("ERROR :",conditionMessage(e), "\n")
  list(weighted_LR_stat = NA,
       weighted_mean = NA,
       weighted_var = NA,
       weighted_sigma.sq = NA,
       weighted_tau.sq = NA,
       weighted_prop_sv = NA)
  })
  return(res)
}

weighted_nnSVG_list <- lapply(c(1:dim(spe)[1]), weighted_nnSVG_calc)

save(spe_unweighted, weighted_nnSVG_list, file = "spe_simulation_weighted_nnSVG.Rdata")

```

```{r}
library(ggplot2)
library(SpatialExperiment)
library(patchwork)
library(GGally)
library(dplyr)
library(ggridges)

### EXPLORING CHANGING RANKS
#prop sv, sigma.sq, LR pre weighting, LR post weighting, etc.

#load(file = "mean_var_project/spe_simulation_weighted_nnSVG.Rdata")
load(file = "mean_var_project/simulation/poisson_4/spe_simulation_weighted_constrained_nnSVG.Rdata")

pdf(file="mean_var_project/simulation/poisson_4/simulation_vis.pdf")

weighted_rank <- rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')])))

#new value for change in rank
rank_shift <- rowData(spe_unweighted)$rank - weighted_rank

#load(file = "simulation_BRISC_estimation_spline.rds")
load(file = "mean_var_project/simulation/poisson_4/constrained_weights.rds")
w <- w_new

weighted_logcounts <- t(w)*logcounts(spe_unweighted)
weighted_mean <- rowMeans(weighted_logcounts)

#check if genes with spatial variation ranked higher compared to genes without spatial variation
rank_unw <- data.frame(
  y = rowData(spe_unweighted)$rank,
  x = rowData(spe_unweighted)$mean,
  ground_truth_sigma.sq = rowData(spe_unweighted)$ground_truth_sigma.sq
) |> 
  ggplot() +
  geom_point(aes(x = x, y = y, col = ground_truth_sigma.sq)) +
  labs(
    x = "unw mean of logcounts",
    y = "rank",
    title = "unweighted nnSVG",
    caption = cor.test(rowData(spe_unweighted)$rank, rowData(spe_unweighted)$ground_truth_rank, method = 'spearman')[4]
  )

rank_w <- data.frame(
  y = rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')]))),
  x = weighted_mean,
  ground_truth_sigma.sq = rowData(spe_unweighted)$ground_truth_sigma.sq
) |> 
  ggplot() +
  geom_point(aes(x = x, y = y, col = ground_truth_sigma.sq)) +
  labs(
    x = "w mean of logcounts",
    y = "rank",
    title = "constrained weighted nnSVG",
    caption = cor.test(rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')]))), rowData(spe_unweighted)$ground_truth_rank, method = 'spearman')[4]
  )

wrap_plots(rank_unw, rank_w, 
           guides = "collect",
           ncol=2, nrow=1)

#overlay unweighted and constrained weighted ridge plots
df_unw <- data.frame(
  rank = rowData(spe_unweighted)$rank,
  mean = rowData(spe_unweighted)$mean,
  method = rep("unw", 1000) 
) %>% mutate(quantile = findInterval(mean, 
                quantile(mean, probs=0:9/10))) %>%
  tibble::rownames_to_column()

df_cw <- data.frame(
  rank = rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')]))),
  mean = weighted_mean,
  method = rep("cw", 1000) 
) %>% mutate(quantile = findInterval(mean, 
                quantile(mean, probs=0:9/10))) %>%
  tibble::rownames_to_column()

df <- rbind(df_unw, df_cw) %>% 
  mutate(quantile = as.factor(quantile))

rank_overlay <- ggplot(df, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = method), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - unw & w mean of logcounts",
    x = "rank",
    title = "Ridge plots: effect of weighting on rank"
  ) +
  scale_fill_manual(labels = c("weighted", "unweighted"), values = c("blue", "red")) +
  theme_bw()

print(rank_overlay)

#overlay unweighted and constrained weighted ridge plots for unw mean
df_unw_2 <- data.frame(
  rank = rowData(spe_unweighted)$rank,
  mean = rowData(spe_unweighted)$mean,
  method = rep("unw", 1000) 
) %>% mutate(quantile = findInterval(mean, 
                quantile(mean, probs=0:9/10))) %>%
  tibble::rownames_to_column()

df_cw_2 <- data.frame(
  rank = rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')]))),
  mean = rowData(spe_unweighted)$mean,
  method = rep("cw", 1000) 
) %>% mutate(quantile = findInterval(mean, 
                quantile(mean, probs=0:9/10))) %>%
  tibble::rownames_to_column()

df_2 <- rbind(df_unw_2, df_cw_2) %>% 
  mutate(quantile = as.factor(quantile))

rank_overlay <- ggplot(df_2, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = method), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - unw mean of logcounts",
    x = "rank",
    title = "Ridge plots: effect of weighting on rank"
  ) +
  scale_fill_manual(labels = c("weighted", "unweighted"), values = c("blue", "red")) +
  theme_bw()

print(rank_overlay)

#ridge plots separated by noise and signal for unw and constrained

frac <- round(dim(spe_unweighted)[1]*0.1)*0.1

df_unw_signal <- df_unw %>%
  mutate(quantile = as.factor(quantile)) %>%
  group_by(quantile) %>%
  slice_min(order_by = rank, n = frac) %>%
  mutate(grp = "signal")

indices <- as.integer(df_unw_signal$rowname)

df_unw_background <- df_unw[-indices,] %>%
  mutate(quantile = as.factor(quantile)) %>%
  mutate(grp = "background")

df <- rbind(df_unw_signal, df_unw_background)

rank_separated_unw <- ggplot(df, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = grp), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - unw mean of logcounts",
    x = "rank",
    title = "Signal unweighted"
  ) +
  guides(fill=guide_legend(title="group")) +
  theme_bw() 
  

df_cw_signal <- df_cw %>%
  mutate(quantile = as.factor(quantile)) %>%
  group_by(quantile) %>%
  slice_min(order_by = rank, n = frac) %>%
  mutate(grp = "signal")

indices <- as.integer(df_cw_signal$rowname)

df_cw_background <- df_cw[-indices,] %>%
  mutate(quantile = as.factor(quantile)) %>%
  mutate(grp = "background")

df <- rbind(df_cw_signal, df_cw_background)

rank_separated_cw <- ggplot(df, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = grp), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - w mean of logcounts",
    x = "rank",
    title = "Signal weighted"
  )  +
  guides(fill=guide_legend(title="group")) +
  theme_bw() 

wrap_plots(rank_separated_unw, rank_separated_cw, nrow=1, guides = "collect") 

#ridge plots separated by noise and signal for unw and constrained for unw mean only

frac <- round(dim(spe_unweighted)[1]*0.1)*0.1

df_unw_signal_2 <- df_unw_2 %>%
  mutate(quantile = as.factor(quantile)) %>%
  group_by(quantile) %>%
  slice_min(order_by = rank, n = frac) %>%
  mutate(grp = "signal")

indices <- as.integer(df_unw_signal_2$rowname)

df_unw_background_2 <- df_unw_2[-indices,] %>%
  mutate(quantile = as.factor(quantile)) %>%
  mutate(grp = "background")

df_2 <- rbind(df_unw_signal_2, df_unw_background_2)

rank_separated_unw_2 <- ggplot(df_2, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = grp), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - unw mean of logcounts",
    x = "rank",
    title = "Signal unweighted"
  ) +
  guides(fill=guide_legend(title="group")) +
  theme_bw() 
  

df_cw_signal_2 <- df_cw_2 %>%
  mutate(quantile = as.factor(quantile)) %>%
  group_by(quantile) %>%
  slice_min(order_by = rank, n = frac) %>%
  mutate(grp = "signal")

indices <- as.integer(df_cw_signal_2$rowname)

df_cw_background_2 <- df_cw_2[-indices,] %>%
  mutate(quantile = as.factor(quantile)) %>%
  mutate(grp = "background")

df_2 <- rbind(df_cw_signal_2, df_cw_background_2)

rank_separated_cw_2 <- ggplot(df_2, aes(x = rank, y = quantile)) +
  geom_density_ridges2(aes(fill = grp), rel_min_height = 0.02, alpha = 0.3) +
  theme_ridges(grid = TRUE) +
  labs(
    y = "decile - unw mean of logcounts",
    x = "rank",
    title = "Signal weighted"
  )  +
  guides(fill=guide_legend(title="group")) +
  theme_bw() 

wrap_plots(rank_separated_unw_2, rank_separated_cw_2, nrow=1, guides = "collect") 


dev.off()

ggsave("proposal/fig4b.png",wrap_plots(rank_separated_unw, rank_separated_cw, nrow=1, guides = "collect") )


#compare all means 
mean_data <- data.frame(unweighted_mean = rowData(spe_unweighted)$mean,
                        con_weighted_mean = unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_mean')])),
                        beta = rowData(spe_unweighted)$ground_truth_beta,
                        raw_mean = rowMeans(logcounts(spe_unweighted)))

ggpairs(mean_data, aes(alpha = 0.4))

dev.off()

#trying out different correlations

all_data <- data.frame(
  ground_truth_sigma.sq = rowData(spe_unweighted)$ground_truth_sigma.sq,
  unweighted_sigma.sq = rowData(spe_unweighted)$sigma.sq,
  weighted_sigma.sq = unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_sigma.sq')])),
  unweighted_tau.sq = rowData(spe_unweighted)$tau.sq,
  weighted_tau.sq = unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_tau.sq')])),
  unweighted_prop_sv = rowData(spe_unweighted)$prop_sv,
  weighted_prop_sv = unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_prop_sv')])),
  ground_truth_beta = rowData(spe_unweighted)$ground_truth_beta,
  ground_truth_rank = rowData(spe_unweighted)$ground_truth_rank,
  unweighted_rank = rowData(spe_unweighted)$rank,
  weighted_rank = rank(-1*unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')]))),
  unweighted_LR_stat = rowData(spe_unweighted)$LR_stat,
  weighted_LR_stat = unlist(lapply(weighted_nnSVG_list, function (x) x[c('weighted_LR_stat')])),
  ground_truth = rowData(spe_unweighted)$ground_truth
)

#calculate spearman correlation between unweighted & ground truth = -0.74
corr.unweighted <- cor.test(all_data$ground_truth_rank, all_data$unweighted_rank, method = 'spearman')

library(coin)
spearman_test(all_data$ground_truth_rank ~ all_data$unweighted_rank)

library(Hmisc)
rcorr(all_data$ground_truth_rank, all_data$unweighted_rank, type="spearman")

#calculate spearman correlation between weighted & ground truth = -0.11
corr.weighted <- cor.test(all_data$ground_truth_rank, all_data$weighted_rank, method = 'spearman')

library(coin)
spearman_test(all_data$ground_truth_rank ~ all_data$weighted_rank)

library(Hmisc)
rcorr(all_data$ground_truth_rank, all_data$weighted_rank, type="spearman")

#calculate spearman correlation only for ground truth SVG genes 
#need to re rank genes 
library(dplyr)
cor.test(filter(all_data, ground_truth == TRUE)$ground_truth_rank, rank(-1*filter(all_data, ground_truth == TRUE)$unweighted_LR_stat))
cor.test(filter(all_data, ground_truth == TRUE)$ground_truth_rank,rank(-1*filter(all_data, ground_truth == TRUE)$weighted_LR_stat))

```

